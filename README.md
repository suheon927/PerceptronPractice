# Perceptron Practice

This repository is focused on building and experimenting with perceptron models.

## Current Project: 4-Input XOR Operation

### Overview
The project implements a **Multi-Layer Perceptron (MLP)** to solve the XOR problem with 4 inputs. XOR is a non-linearly separable problem, and solving it demonstrates the power of MLPs over single-layer perceptrons.

### Model Details
- **Input Size:** 4
- **Operation:** XOR
- **Architecture:** Multi-Layer Perceptron (MLP)
- **Current Status:** In development

### Progress
- **Activation Functions:** Non-linear (e.g., Sigmoid or ReLU) to be tested
- **Hidden Layers:** Exploring 1 and 2 hidden layer models with 16 neurons each
- **Goal:** Achieve accurate XOR results with 4 inputs using MLP

### Planned Work
- Test and implement non-linear activation functions.
- Experiment with different numbers of hidden layers and neurons.
- Refine model performance and accuracy.

## How to Run
1. Clone this repository:
    ```bash
    git clone https://github.com/your-username/perceptron-practice.git
    ```
2. Navigate to the project directory:
    ```bash
    cd perceptron-practice
    ```
3. Run the model (instructions for how to run it once fully developed).

## License
This project is open-source under the [MIT License](LICENSE).
